{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street View House Numbers\n",
    "\n",
    "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images. \n",
    "\n",
    "These are the original, variable-resolution, color house-number images with character level bounding boxes, as shown in the examples images above. (The blue bounding boxes here are just for illustration purposes. The bounding box information are stored in digitStruct.mat instead of drawn directly on the images in the dataset.) Each tar.gz file contains the orignal images in png format, together with a digitStruct.mat file, which can be loaded using Matlab. The digitStruct.mat file contains a struct called digitStruct with the same length as the number of original images. Each element in digitStruct has the following fields: name which is a string containing the filename of the corresponding image. bbox which is a struct array that contains the position, size and label of each digit bounding box in the image. Eg: digitStruct(300).bbox(2).height gives height of the 2nd digit bounding box in the 300th image. \n",
    "\n",
    "* Dataset link:\n",
    "http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "To correctly detect a series of numbers given an image of house\n",
    "numbers by training a convolutional neural network with multiple\n",
    "layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The future statement is intended to ease migration to future versions of Python that introduce incompatible changes to the language. It allows use of the new features on a per-module basis before the release in which the feature becomes standard.\n",
    "__future__ is a pseudo-module which programmers can use to enable new language features which are not compatible with the current interpreter. For example, the expression 11/4 currently evaluates to 2. If the module in which it is executed had enabled true division by executing:\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "the expression 11/4 would evaluate to 2.75.\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "* six\n",
    "Six is a Python 2 and 3 compatibility library. It provides utility functions for smoothing over the differences between the Python versions with the goal of writing Python code that is compatible on both Python versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import pickle\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_folder = '/train'\n",
    "test_folder ='/test'\n",
    "extra_folder = '/extra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Aegis\\\\Python\\\\Jupyter Notebook\\\\Projects\\\\SVHM'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filename, directory name, or volume label syntax is incorrect.\n"
     ]
    }
   ],
   "source": [
    "### 1. Creating Dictionary for bounded box information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* h5 file\n",
    "An H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data. ... Two commonly used versions of HDF include HDF4 and HDF5 \n",
    "\n",
    "* HDF5 for Python\n",
    "The h5py package is a Pythonic interface to the HDF5 binary data format.\n",
    "\n",
    "It lets you store huge amounts of numerical data, and easily manipulate that data from NumPy. For example, you can slice into multi-terabyte datasets stored on disk, as if they were real NumPy arrays. Thousands of datasets can be stored in a single file, categorized and tagged however you want.\n",
    "\n",
    "H5py uses straightforward NumPy and Python metaphors, like dictionary and NumPy array syntax.\n",
    "\n",
    "mat files are actually saved using the HDF5 format by default "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Throws NotImplementedError: Please use HDF reader for matlab v7.3 files\n",
    "\n",
    "import scipy.io\n",
    "digitMat = scipy.io.loadmat('./train/digitStruct.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<HDF5 object reference>, dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "struct_file = './train/digitStruct.mat'\n",
    "file = h5py.File(struct_file,'r')\n",
    "data = file.get('/digitStruct/name').value[0].item()\n",
    "d2 = np.array(data)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " List of dataset in this file is  ['#refs#', 'digitStruct']\n",
      " Shape of file is  (33402, 1)\n",
      " Shape of file is  (33402, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "with h5py.File('./train/digitStruct.mat','r') as hdf:\n",
    "    ls = list(hdf.keys())\n",
    "    print(\" List of dataset in this file is \",ls)\n",
    "    data = hdf.get('/digitStruct/name')\n",
    "    data1 = hdf.get('/digitStruct/bbox')\n",
    "    d1 = np.array(data)\n",
    "    d2 = np.array(data1)\n",
    "    print(\" Shape of file is \",d1.shape)\n",
    "    print(\" Shape of file is \",d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50]\n",
      " [ 46]\n",
      " [112]\n",
      " [110]\n",
      " [103]]\n",
      "<HDF5 group \"/#refs#/7Qi\" (5 members)>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "struct_file = './train/digitStruct.mat'\n",
    "file = h5py.File(struct_file)\n",
    "name = file.get('/digitStruct/name').value[1][0] # <HDF5 object reference>\n",
    "bbox = file.get('/digitStruct/bbox').value[1][0]\n",
    "print(file[name].value)\n",
    "print(file[bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DigitStructFile:\n",
    "    '''The DigitStructFile references the following \n",
    "    file:              The input h5 matlab file\n",
    "    digitStructName   The h5 reference to all the file names\n",
    "    digitStructBbox   The h5 reference to all struc data'''\n",
    "    def __init__(self,file):\n",
    "        self.file = h5py.File(file, 'r') #Create a new file object.\n",
    "        self.digitStructName = self.file['digitStruct']['name']\n",
    "        self.digitStructBox = self.file['digitStruct']['bbox']\n",
    "        \n",
    "    def getName(self,n):\n",
    "        '''Returns name string for the nth digitStruct '''\n",
    "        return ''.join([chr(c[0]) for c in self.file[self.digitStructName[n][0]].value])\n",
    "    \n",
    "    def bboxHelper(self,attr):\n",
    "        if len(attr) > 1:\n",
    "            attr = [self.file[attr.value[j].item()].value[0][0] for j in range(len(attr))]\n",
    "        else:\n",
    "            attr = [attr.value[0][0]]\n",
    "        return attr\n",
    "    \n",
    "    def getBbox(self,n):\n",
    "        '''Returns a dict of data for the n(th) bbox '''\n",
    "        bbox ={}\n",
    "        bb = self.digitStructBox[n].item()    \n",
    "        bbox['height'] = self.bboxHelper(self.file[bb]['height'])\n",
    "        bbox['label'] = self.bboxHelper(self.file[bb]['label'])\n",
    "        bbox['left'] = self.bboxHelper(self.file[bb]['left'])\n",
    "        bbox['top'] = self.bboxHelper(self.file[bb]['top'])\n",
    "        bbox['width'] = self.bboxHelper(self.file[bb]['width'])\n",
    "        return bbox\n",
    "    \n",
    "    def getDigitStruct(self,n):\n",
    "        '''Returns the structure of the digitStruct'''\n",
    "        struct = self.getBbox(n)\n",
    "        struct['name'] = self.getName(n)\n",
    "        return struct\n",
    "    \n",
    "    def getAllDigitStruct(self):\n",
    "        '''Returns all the digitStruct from the input file'''\n",
    "        return [self.getDigitStruct(i) for i in range(len(self.digitStructName))]\n",
    "    \n",
    "    def getAllDigitStruct_Digit(self):\n",
    "        digit_pic = self.getAllDigitStruct()\n",
    "        result=[]\n",
    "        structCnt = 1\n",
    "        for i in range(len(digit_pic)):\n",
    "            item = {'filename':digit_pic[i]['name']}\n",
    "            figures=[]\n",
    "            for j in range(len(digit_pic[i]['height'])):\n",
    "                figure = {}\n",
    "                figure['height'] = digit_pic[i]['height'][j]\n",
    "                figure['label'] = digit_pic[i]['label'][j]\n",
    "                figure['left'] = digit_pic[i]['left'][j]\n",
    "                figure['top'] = digit_pic[i]['top'][j]\n",
    "                figure['width'] = digit_pic[i]['width'][j]\n",
    "                figures.append(figure)\n",
    "            structCnt+=1\n",
    "            item['boxes'] = figures\n",
    "            result.append(item)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Processing Data  2019-04-09 13:58:53.670203\n",
      "End of Processing Data  2019-04-09 14:42:52.198866\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "digitStructFileTrain = DigitStructFile(os.path.join('train','digitStruct.mat'))\n",
    "digitStructFileTest = DigitStructFile(os.path.join('test','digitStruct.mat'))\n",
    "digitStructFileExtra = DigitStructFile(os.path.join('extra','digitStruct.mat'))\n",
    "\n",
    "print(\"Start of Processing Data \",datetime.datetime.now())\n",
    "train_data = digitStructFileTrain.getAllDigitStruct_Digit()\n",
    "test_data = digitStructFileTest.getAllDigitStruct_Digit()\n",
    "extra_data = digitStructFileExtra.getAllDigitStruct_Digit()\n",
    "\n",
    "print(\"End of Processing Data \",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [{'height': 219.0,\n",
       "   'label': 1.0,\n",
       "   'left': 246.0,\n",
       "   'top': 77.0,\n",
       "   'width': 81.0},\n",
       "  {'height': 219.0, 'label': 9.0, 'left': 323.0, 'top': 81.0, 'width': 96.0}],\n",
       " 'filename': '1.png'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note train_data is list of dictionary\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [{'height': 50.0,\n",
       "   'label': 6.0,\n",
       "   'left': 60.0,\n",
       "   'top': 11.0,\n",
       "   'width': 24.0},\n",
       "  {'height': 50.0, 'label': 10.0, 'left': 87.0, 'top': 9.0, 'width': 24.0},\n",
       "  {'height': 50.0, 'label': 1.0, 'left': 113.0, 'top': 7.0, 'width': 21.0}],\n",
       " 'filename': '25.png'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[24] # This has digit 601 on it, Note how this is misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [{'height': 16.0,\n",
       "   'label': 5.0,\n",
       "   'left': 24.0,\n",
       "   'top': 4.0,\n",
       "   'width': 10.0},\n",
       "  {'height': 16.0, 'label': 1.0, 'left': 34.0, 'top': 5.0, 'width': 7.0},\n",
       "  {'height': 16.0, 'label': 5.0, 'left': 40.0, 'top': 5.0, 'width': 11.0}],\n",
       " 'filename': '22.png'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[21] # Has digit 515 on it. Note how height and top are the same (makes absolute sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'height': 16.0, 'label': 5.0, 'left': 24.0, 'top': 4.0, 'width': 10.0},\n",
       " {'height': 16.0, 'label': 1.0, 'left': 34.0, 'top': 5.0, 'width': 7.0},\n",
       " {'height': 16.0, 'label': 5.0, 'left': 40.0, 'top': 5.0, 'width': 11.0}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[21]['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[21]['boxes'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22.png'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[21]['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop images using bounded box information"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PIL\n",
    "#PIL is the Python Imaging Library(in newer versions known as Pillow)\n",
    "\n",
    "#Adds support for opening, manipulating, and saving many different image file formats.\n",
    "\n",
    "#The Image module provides a class with the same name which is used to represent a PIL image. The module also provides a number of factory functions, including functions to load images from files, and to create new images.\n",
    "\n",
    "from PIL import Image\n",
    "im = Image.open(\"F:\\\\Aegis\\\\Python\\\\Jupyter Notebook\\\\Projects\\\\SVHM\\\\train\\\\58.jpg\")\n",
    "im.rotate(45).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Aegis\\\\Python\\\\Jupyter Notebook\\\\Projects\\\\SVHM'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876.0 501.0\n",
      "25.0 12.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "#Creating a numpy array with rows = number of images and 2 columns\n",
    "train_imsize = np.ndarray([len(train_data),2])\n",
    "#print(\"Sample \",train_imsize[0:5,:])\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    filename = train_data[i]['filename']\n",
    "    #print(filename)\n",
    "    fullname = os.path.join('train',filename)\n",
    "    im = Image.open(fullname)\n",
    "    #im.show()\n",
    "    train_imsize[i,:] = im.size[:]\n",
    "    #if i == 10:\n",
    "    #    break\n",
    "\n",
    "#print(train_imsize[0:5,:])\n",
    "print(np.amax(train_imsize[:,0]), np.amax(train_imsize[:,1]))\n",
    "print(np.amin(train_imsize[:,0]), np.amin(train_imsize[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 33)\n"
     ]
    }
   ],
   "source": [
    "a = np.ndarray([2,3])\n",
    "a\n",
    "l = im.size[:]\n",
    "print(l)\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083.0 516.0\n",
      "31.0 13.0\n"
     ]
    }
   ],
   "source": [
    "test_imsize = np.ndarray([len(test_data),2])\n",
    "for i in np.arange(len(test_data)):\n",
    "    filename = test_data[i]['filename']\n",
    "    fullname = os.path.join('test', filename)\n",
    "    im = Image.open(fullname)\n",
    "    test_imsize[i, :] = im.size[:]\n",
    "\n",
    "print(np.amax(test_imsize[:,0]), np.amax(test_imsize[:,1]))\n",
    "print(np.amin(test_imsize[:,0]), np.amin(test_imsize[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668.0 415.0\n",
      "22.0 13.0\n"
     ]
    }
   ],
   "source": [
    "extra_imsize = np.ndarray([len(extra_data),2])\n",
    "for i in np.arange(len(extra_data)):\n",
    "    filename = extra_data[i]['filename']\n",
    "    fullname = os.path.join('extra', filename)\n",
    "    im = Image.open(fullname)\n",
    "    extra_imsize[i, :] = im.size[:]\n",
    "\n",
    "print(np.amax(extra_imsize[:,0]), np.amax(extra_imsize[:,1]))\n",
    "print(np.amin(extra_imsize[:,0]), np.amin(extra_imsize[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute extra image dataset and remove images with more than 5 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 29929 image has more than 5 digits.\n",
      "(33402, 32, 32, 1) (33402, 6)\n",
      "(13068, 32, 32, 1) (13068, 6)\n",
      "(202353, 32, 32, 1) (202353, 6)\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "\n",
    "def generate_dataset(data, folder):\n",
    "\n",
    "    dataset = np.ndarray([len(data),32,32,1], dtype='float32')\n",
    "    labels = np.ones([len(data),6], dtype=int) * 10\n",
    "    for i in np.arange(len(data)):\n",
    "        filename = data[i]['filename']\n",
    "        fullname = os.path.join(folder, filename)\n",
    "        im = Image.open(fullname)\n",
    "        boxes = data[i]['boxes'] #returns list of dictionaries of number of digits\n",
    "        num_digit = len(boxes) \n",
    "        labels[i,0] = num_digit\n",
    "        print(\"labels \",labels)\n",
    "        top = np.ndarray([num_digit], dtype='float32')\n",
    "        print(\"top \",top)\n",
    "        left = np.ndarray([num_digit], dtype='float32')\n",
    "        height = np.ndarray([num_digit], dtype='float32')\n",
    "        width = np.ndarray([num_digit], dtype='float32')\n",
    "        print(\"width \",width)\n",
    "        for j in np.arange(num_digit):\n",
    "            if j < 5: \n",
    "                labels[i,j+1] = boxes[j]['label']\n",
    "                if boxes[j]['label'] == 10:\n",
    "                    labels[i,j+1] = 0\n",
    "            else:\n",
    "                print('Image number ',i,' has more than 5 digits')\n",
    "            ''' Storing top, left, width, height of all the digits of the image in a list '''\n",
    "            top[j] = boxes[j]['top']\n",
    "            left[j] = boxes[j]['left']\n",
    "            height[j] = boxes[j]['height']\n",
    "            width[j] = boxes[j]['width']\n",
    "        \n",
    "        im_top = np.amin(top)\n",
    "        im_left = np.amin(left)\n",
    "        im_height = np.amax(top) + height[np.argmax(top)] - im_top\n",
    "        im_width = np.amax(left) + width[np.argmax(left)] - im_left\n",
    "        \n",
    "        im_top = np.floor(im_top - 0.1 * im_height)\n",
    "        im_left = np.floor(im_left - 0.1 * im_width)\n",
    "        im_bottom = np.amin([np.ceil(im_top + 1.2 * im_height), im.size[1]])\n",
    "        im_right = np.amin([np.ceil(im_left + 1.2 * im_width), im.size[0]])\n",
    "\n",
    "        im = im.crop((im_left, im_top, im_right, im_bottom)).resize([32,32], Image.ANTIALIAS)\n",
    "        im = np.dot(np.array(im, dtype='float32'), [[0.2989],[0.5870],[0.1140]])\n",
    "        mean = np.mean(im, dtype='float32')\n",
    "        std = np.std(im, dtype='float32', ddof=1)\n",
    "        if std < 1e-4: std = 1.\n",
    "        im = (im - mean) / std\n",
    "        dataset[i,:,:,:] = im[:,:,:]\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = generate_dataset(train_data, 'train')\n",
    "print(train_dataset.shape, train_labels.shape)\n",
    "\n",
    "test_dataset, test_labels = generate_dataset(test_data, 'test')\n",
    "print(test_dataset.shape, test_labels.shape)\n",
    "\n",
    "extra_dataset, extra_labels = generate_dataset(extra_data, 'extra')\n",
    "print(extra_dataset.shape, extra_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [2,3,4,5]\n",
    "np.argmax(t)+np.max(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(train_dataset)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33401, 32, 32, 1) (33401, 6)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.delete(train_dataset, 29929, axis=0)\n",
    "train_labels = np.delete(train_labels, 29929, axis=0)\n",
    "\n",
    "print(train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230070, 32, 32, 1) (230070, 6)\n",
      "(13068, 32, 32, 1) (13068, 6)\n",
      "(5684, 32, 32, 1) (5684, 6)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed()\n",
    "\n",
    "n_labels = 10\n",
    "valid_index = []\n",
    "valid_index2 = []\n",
    "train_index = []\n",
    "train_index2 = []\n",
    "for i in np.arange(n_labels):\n",
    "    valid_index.extend(np.where(train_labels[:,1] == (i))[0][:400].tolist())\n",
    "    train_index.extend(np.where(train_labels[:,1] == (i))[0][400:].tolist())\n",
    "    valid_index2.extend(np.where(extra_labels[:,1] == (i))[0][:200].tolist())\n",
    "    train_index2.extend(np.where(extra_labels[:,1] == (i))[0][200:].tolist())\n",
    "\n",
    "random.shuffle(valid_index)\n",
    "random.shuffle(train_index)\n",
    "random.shuffle(valid_index2)\n",
    "random.shuffle(train_index2)\n",
    "\n",
    "valid_dataset = np.concatenate((extra_dataset[valid_index2,:,:,:], train_dataset[valid_index,:,:,:]), axis=0)\n",
    "valid_labels = np.concatenate((extra_labels[valid_index2,:], train_labels[valid_index,:]), axis=0)\n",
    "train_dataset_t = np.concatenate((extra_dataset[train_index2,:,:,:], train_dataset[train_index,:,:,:]), axis=0)\n",
    "train_labels_t = np.concatenate((extra_labels[train_index2,:], train_labels[train_index,:]), axis=0)\n",
    "\n",
    "print(train_dataset_t.shape, train_labels_t.shape)\n",
    "print(test_dataset.shape, test_labels.shape)\n",
    "print(valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 1025147176\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a pickle file to store processed data\"\"\"\n",
    "pickle_file = 'SVHN_multi.pickle'\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    dict_data = {\n",
    "    'train_dataset': train_dataset_t,\n",
    "    'train_labels': train_labels_t,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "    pickle.dump(dict_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
